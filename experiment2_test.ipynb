{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import diagnostic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = [\"rois_aal\", \"rois_cc200\", \"rois_cc400\", \"rois_dosenbach160\", \"rois_ez\", \"rois_ho\", \"rois_tt\"]\n",
    "pipelines = [\"cpac\", \"niak\"]\n",
    "strategies = [\"filt_global\", \"filt_noglobal\", \"nofilt_global\", \"nofilt_noglobal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m strategies:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Run the model; download data if needed, collect features and labels, train and test algorithm, collect performance metrics\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         model_performance \u001b[38;5;241m=\u001b[39m \u001b[43mdiagnostic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_diagnostic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mderivative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderivative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in model execution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/ASD-Diagnostic_Research_2023-24/diagnostic_model.py:240\u001b[0m, in \u001b[0;36mtest_diagnostic_model\u001b[0;34m(derivative, strategy, pipeline, algorithm, k, print_stats)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_diagnostic_model\u001b[39m(derivative, strategy, pipeline, algorithm, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, print_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    238\u001b[0m     download_data(desired_derivative\u001b[38;5;241m=\u001b[39mderivative, desired_strategy\u001b[38;5;241m=\u001b[39mstrategy, desired_pipeline\u001b[38;5;241m=\u001b[39mpipeline, print_stats\u001b[38;5;241m=\u001b[39mprint_stats)\n\u001b[0;32m--> 240\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mderivative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderivative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_test_fMRI_data(fMRI_features\u001b[38;5;241m=\u001b[39mfeatures, labels\u001b[38;5;241m=\u001b[39mlabels, algorithm\u001b[38;5;241m=\u001b[39malgorithm, k\u001b[38;5;241m=\u001b[39mk, print_stats\u001b[38;5;241m=\u001b[39mprint_stats)\n",
      "File \u001b[0;32m/workspaces/ASD-Diagnostic_Research_2023-24/diagnostic_model.py:89\u001b[0m, in \u001b[0;36mfeatures_and_labels\u001b[0;34m(pipeline, derivative, strategy, print_stats)\u001b[0m\n\u001b[1;32m     87\u001b[0m download_asd_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabide_preprocessed_dataset/ASD/Outputs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mderivative\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Make features and labels arrays for ASD data\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m features_asd \u001b[38;5;241m=\u001b[39m \u001b[43mgather_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_asd_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m labels_asd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(features_asd)) \u001b[38;5;66;03m# Label 1 for ASD, 0 for TDC\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Specify the path to the directory containing the downloaded preprocessed data for TDC data\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/ASD-Diagnostic_Research_2023-24/diagnostic_model.py:62\u001b[0m, in \u001b[0;36mgather_features\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Check if the file is a timeseries file \u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.1D\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Load the timeseries data \u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     timeseries_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_timeseries_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Append features\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(timeseries_data)\n",
      "File \u001b[0;32m/workspaces/ASD-Diagnostic_Research_2023-24/diagnostic_model.py:73\u001b[0m, in \u001b[0;36mload_timeseries_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_timeseries_data\u001b[39m(file_path):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Load timeseries data from the 1D file\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 73\u001b[0m         timeseries \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m timeseries\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_count = 1\n",
    "column_titles = [\"Model #\", \"ML Algorithm\", \"Derivative\", \"Preprocessing Pipeline\", \"Preprocessing Strategy\",\n",
    "                \"Sensitivity\", \"Specificity\", \"Precision\", \"F1 Score\", \"Accuracy\",\n",
    "                \"True Positives\", \"True Negatives\", \"False Positives\", \"False Negatives\"]\n",
    "experiment_data = pd.DataFrame(columns=column_titles)\n",
    "\n",
    "# Logistic Regression tests\n",
    "for derivative in derivatives:\n",
    "    for pipeline in pipelines:\n",
    "        for strategy in strategies:\n",
    "            try:\n",
    "                # Run the model; download data if needed, collect features and labels, train and test algorithm, collect performance metrics\n",
    "                model_performance = diagnostic_model.test_diagnostic_model(derivative=derivative, strategy=strategy, pipeline=pipeline, algorithm=\"LR\", print_stats=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in model execution: {e}\")\n",
    "\n",
    "            # Add the model's performance metrics to experiment data\n",
    "            model_data = [model_count, \"LR\", derivative, pipeline, strategy] + model_performance[1:4] + model_performance[0] + model_performance[5:8]\n",
    "            experiment_data = experiment_data.append(pd.Series(model_data, index=column_titles), ignore_index=True)\n",
    "\n",
    "            print(\"Model-{model_count}'s testing has been completed!\")\n",
    "            model_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before script execution: 365.74 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x7f5844be9750>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/core.py\", line 589, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil \n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(f\"Memory usage before script execution: {process.memory_info().rss / (1024 ** 2):.2f} MB\")\n",
    "try:\n",
    "    diagnostic_model.test_diagnostic_model(derivative=\"rois_aal\", strategy=\"filt_global\", pipeline=\"cpac\", algorithm=\"LR\", print_stats=False)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "print(f\"Memory usage after script execution: {process.memory_info().rss / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 4.1%\n",
      "Memory Usage: 31.5%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get CPU and memory usage\n",
    "cpu_usage = psutil.cpu_percent(interval=1)\n",
    "memory_usage = psutil.virtual_memory()\n",
    "print(f\"CPU Usage: {cpu_usage}%\")\n",
    "print(f\"Memory Usage: {memory_usage.percent}%\")\n",
    "\n",
    "try:\n",
    "    diagnostic_model.test_diagnostic_model(derivative=\"rois_aal\", strategy=\"filt_global\", pipeline=\"cpac\", algorithm=\"LR\", kFold=False, print_stats=False)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Get CPU and memory usage\n",
    "cpu_usage = psutil.cpu_percent(interval=1)\n",
    "memory_usage = psutil.virtual_memory()\n",
    "print(f\"CPU Usage: {cpu_usage}%\")\n",
    "print(f\"Memory Usage: {memory_usage.percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
